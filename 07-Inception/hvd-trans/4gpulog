2022-03-15 20:17:33.320739: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:33.320739: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:33.324249: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:33.324250: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   dl019
  Local device: mlx4_0
--------------------------------------------------------------------------
2022-03-15 20:17:34.445183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2022-03-15 20:17:34.445183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2022-03-15 20:17:34.445931: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2022-03-15 20:17:34.445939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2022-03-15 20:17:35.983877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.985455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.988185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.989256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.989823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.992343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.996262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:35.996870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.000005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.000042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.000124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.000961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.001574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.001610: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.003710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.003728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.003754: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.005344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.006954: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:36.007022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:36.006972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.007006: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.007653: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:36.007718: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:36.010519: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2022-03-15 20:17:36.010657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2022-03-15 20:17:36.010915: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2022-03-15 20:17:36.011001: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2022-03-15 20:17:36.011119: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:36.011193: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:36.011771: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2022-03-15 20:17:36.011827: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2022-03-15 20:17:36.012187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:36.012235: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:36.013112: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2022-03-15 20:17:36.013256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2022-03-15 20:17:36.013297: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:36.013445: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:36.014405: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2022-03-15 20:17:36.014400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2022-03-15 20:17:36.014684: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2022-03-15 20:17:36.014691: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2022-03-15 20:17:36.015275: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2022-03-15 20:17:36.015283: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2022-03-15 20:17:36.016307: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2022-03-15 20:17:36.016309: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2022-03-15 20:17:36.016442: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:36.016443: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:36.051309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
2022-03-15 20:17:36.053040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
2022-03-15 20:17:36.053122: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 20:17:36.054146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 20:17:36.065257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:83:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.065324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
2022-03-15 20:17:36.065468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
2022-03-15 20:17:36.065802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.067081: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 20:17:36.067180: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 20:17:36.071088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 2
2022-03-15 20:17:36.071179: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.076037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2022-03-15 20:17:36.076101: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.076099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.076169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:84:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2022-03-15 20:17:36.085866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 1
2022-03-15 20:17:36.085943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:36.085949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 3
2022-03-15 20:17:36.086009: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2022-03-15 20:17:37.357576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-03-15 20:17:37.357622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      1 
2022-03-15 20:17:37.357630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N 
2022-03-15 20:17:37.360172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11396 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1)
2022-03-15 20:17:37.363095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-03-15 20:17:37.363152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2022-03-15 20:17:37.363162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
2022-03-15 20:17:37.365859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11396 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)
2022-03-15 20:17:37.368238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-03-15 20:17:37.368263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      3 
2022-03-15 20:17:37.368271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   N 
2022-03-15 20:17:37.374214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11396 MB memory) -> physical GPU (device: 3, name: NVIDIA TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2022-03-15 20:17:37.374350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-03-15 20:17:37.374382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      2 
2022-03-15 20:17:37.374389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N 
2022-03-15 20:17:37.376905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11396 MB memory) -> physical GPU (device: 2, name: NVIDIA TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
(60000, 28, 28, 1) (60000,)
(10000, 28, 28, 1) (10000,)
Model: "inception"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv_bn_relu (ConvBNRelu)    multiple                  224       
_________________________________________________________________
dynamic-blocks (Sequential)  (None, 7, 7, 128)         292704    
_________________________________________________________________
global_average_pooling2d (Gl multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  1290      
=================================================================
Total params: 294,218
Trainable params: 293,226
Non-trainable params: 992
_________________________________________________________________
2022-03-15 20:17:38.822544: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:38.846463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:38.852070: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:38.871207: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2022-03-15 20:17:39.252316: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8204
2022-03-15 20:17:39.288516: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8204
2022-03-15 20:17:39.294575: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8204
2022-03-15 20:17:39.298497: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8204
[dl019:1062971] 3 more processes have sent help message help-mpi-btl-openib.txt / error in device init
[dl019:1062971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
2022-03-15 20:17:39.692546: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:39.735226: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:39.735517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:39.737028: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2022-03-15 20:17:40.030511: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:40.067243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:40.073523: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:40.076587: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2022-03-15 20:17:42.927560: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2022-03-15 20:17:42.955294: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2022-03-15 20:17:42.980558: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2022-03-15 20:17:42.982702: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2022-03-15 20:17:42.985741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2597015000 Hz
2022-03-15 20:17:42.996523: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2597015000 Hz
2022-03-15 20:17:43.021576: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2597015000 Hz
2022-03-15 20:17:43.022186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2597015000 Hz
0 0 loss: 2.3067923
0 10 loss: 2.0930512
0 20 loss: 1.84964
0 30 loss: 1.4795209
0 40 loss: 0.92314935
0 50 loss: 0.99098825
0 60 loss: 0.5512543
0 70 loss: 0.23337482
0 80 loss: 0.37913758
0 90 loss: 0.23767097
0 100 loss: 0.30883247
0 110 loss: 0.28614438
0 120 loss: 0.2086397
0 130 loss: 0.13743909
0 140 loss: 0.17425968
0 150 loss: 0.15247373
0 160 loss: 0.19160864
0 170 loss: 0.12073454
0 180 loss: 0.21211359
0 190 loss: 0.06944827
0 200 loss: 0.20094335
0 210 loss: 0.13475692
0 220 loss: 0.14163014
0 230 loss: 0.013416279
0 evaluation acc: 0.9628
1 0 loss: 0.12113181
1 10 loss: 0.1092164
1 20 loss: 0.16435616
1 30 loss: 0.23707913
1 40 loss: 0.1894536
1 50 loss: 0.12594748
1 60 loss: 0.20402443
1 70 loss: 0.09623799
1 80 loss: 0.07611944
1 90 loss: 0.07738967
1 100 loss: 0.10583176
1 110 loss: 0.14931849
1 120 loss: 0.096666664
1 130 loss: 0.10994896
1 140 loss: 0.07374884
1 150 loss: 0.08564063
1 160 loss: 0.09277849
1 170 loss: 0.06663041
1 180 loss: 0.10307515
1 190 loss: 0.036598086
1 200 loss: 0.087658465
1 210 loss: 0.060253516
1 220 loss: 0.0815841
1 230 loss: 0.0056635453
1 evaluation acc: 0.979
2 0 loss: 0.059478186
2 10 loss: 0.11886353
2 20 loss: 0.044818897
2 30 loss: 0.090576015
2 40 loss: 0.07993077
2 50 loss: 0.026931778
2 60 loss: 0.07228108
2 70 loss: 0.07780326
2 80 loss: 0.059807118
2 90 loss: 0.031046154
2 100 loss: 0.056560766
2 110 loss: 0.08490071
2 120 loss: 0.07929388
2 130 loss: 0.10662474
2 140 loss: 0.049451865
2 150 loss: 0.06347424
2 160 loss: 0.054793343
2 170 loss: 0.060555443
2 180 loss: 0.06613497
2 190 loss: 0.019705521
2 200 loss: 0.05622198
2 210 loss: 0.043704823
2 220 loss: 0.048025742
2 230 loss: 0.0043830625
2 evaluation acc: 0.9797
3 0 loss: 0.05032359
3 10 loss: 0.109269656
3 20 loss: 0.03520861
3 30 loss: 0.057514925
3 40 loss: 0.04426145
3 50 loss: 0.040727757
3 60 loss: 0.07530327
3 70 loss: 0.089365155
3 80 loss: 0.043194942
3 90 loss: 0.03438824
3 100 loss: 0.043926492
3 110 loss: 0.020464815
3 120 loss: 0.044571564
3 130 loss: 0.045308694
3 140 loss: 0.06430982
3 150 loss: 0.042347714
3 160 loss: 0.03128364
3 170 loss: 0.047764912
3 180 loss: 0.027511451
3 190 loss: 0.010250718
3 200 loss: 0.053841796
3 210 loss: 0.06475401
3 220 loss: 0.024877716
3 230 loss: 0.015137972
3 evaluation acc: 0.9881
4 0 loss: 0.042997777
4 10 loss: 0.1375183
4 20 loss: 0.04121191
4 30 loss: 0.026873069
4 40 loss: 0.026122913
4 50 loss: 0.045302507
4 60 loss: 0.05328146
4 70 loss: 0.058077652
4 80 loss: 0.046998493
4 90 loss: 0.033372477
4 100 loss: 0.026306538
4 110 loss: 0.029261516
4 120 loss: 0.047059037
4 130 loss: 0.032607377
4 140 loss: 0.019893305
4 150 loss: 0.06204484
4 160 loss: 0.02251945
4 170 loss: 0.026304848
4 180 loss: 0.02234463
4 190 loss: 0.0056114453
4 200 loss: 0.06466803
4 210 loss: 0.031529564
4 220 loss: 0.02248211
4 230 loss: 0.00034492151
4 evaluation acc: 0.9894
5 0 loss: 0.030079216
5 10 loss: 0.06530679
5 20 loss: 0.03502322
5 30 loss: 0.015150584
5 40 loss: 0.016689781
5 50 loss: 0.014306888
5 60 loss: 0.05044803
5 70 loss: 0.05992845
5 80 loss: 0.051889125
5 90 loss: 0.025791718
5 100 loss: 0.021817625
5 110 loss: 0.036414176
5 120 loss: 0.02941092
5 130 loss: 0.04910332
5 140 loss: 0.018685361
5 150 loss: 0.0357951
5 160 loss: 0.029903036
5 170 loss: 0.03331302
5 180 loss: 0.04148909
5 190 loss: 0.0050009
5 200 loss: 0.037460398
5 210 loss: 0.021024767
5 220 loss: 0.013998081
5 230 loss: 0.00083627686
5 evaluation acc: 0.9863
6 0 loss: 0.0145916445
6 10 loss: 0.035360742
6 20 loss: 0.03197316
6 30 loss: 0.017982673
6 40 loss: 0.06908484
6 50 loss: 0.022899605
6 60 loss: 0.03498253
6 70 loss: 0.046752907
6 80 loss: 0.04056538
6 90 loss: 0.030181272
6 100 loss: 0.028514383
6 110 loss: 0.018320862
6 120 loss: 0.04296864
6 130 loss: 0.02803669
6 140 loss: 0.020518273
6 150 loss: 0.029181343
6 160 loss: 0.06489886
6 170 loss: 0.05004631
6 180 loss: 0.030241694
6 190 loss: 0.0024533125
6 200 loss: 0.03280716
6 210 loss: 0.024269313
6 220 loss: 0.016297778
6 230 loss: 8.512394e-05
6 evaluation acc: 0.9878
7 0 loss: 0.022556728
7 10 loss: 0.06669264
7 20 loss: 0.0399687
7 30 loss: 0.0126885865
7 40 loss: 0.026106758
7 50 loss: 0.037422907
7 60 loss: 0.0194395
7 70 loss: 0.022753097
7 80 loss: 0.008528941
7 90 loss: 0.032435626
7 100 loss: 0.027812792
7 110 loss: 0.022055143
7 120 loss: 0.026931297
7 130 loss: 0.04744099
7 140 loss: 0.009072954
7 150 loss: 0.018902263
7 160 loss: 0.06515417
7 170 loss: 0.038444705
7 180 loss: 0.03281059
7 190 loss: 0.009910157
7 200 loss: 0.04165045
7 210 loss: 0.01560537
7 220 loss: 0.010872478
7 230 loss: 8.862307e-05
7 evaluation acc: 0.9903
8 0 loss: 0.015284095
8 10 loss: 0.024981996
8 20 loss: 0.024064884
8 30 loss: 0.017320096
8 40 loss: 0.04674136
8 50 loss: 0.02286367
8 60 loss: 0.04273546
8 70 loss: 0.011726075
8 80 loss: 0.0072908965
8 90 loss: 0.030825317
8 100 loss: 0.030937579
8 110 loss: 0.0054006306
8 120 loss: 0.059440214
8 130 loss: 0.031437
8 140 loss: 0.012749409
8 150 loss: 0.013242339
8 160 loss: 0.054103676
8 170 loss: 0.02770323
8 180 loss: 0.006158507
8 190 loss: 0.009547845
8 200 loss: 0.01710338
8 210 loss: 0.023487298
8 220 loss: 0.0076474953
8 230 loss: 2.5906671e-05
8 evaluation acc: 0.9919
9 0 loss: 0.010347045
9 10 loss: 0.04283024
9 20 loss: 0.013446465
9 30 loss: 0.02418887
9 40 loss: 0.018812813
9 50 loss: 0.016560951
9 60 loss: 0.035611328
9 70 loss: 0.037188765
9 80 loss: 0.019767078
9 90 loss: 0.014066677
9 100 loss: 0.013805171
9 110 loss: 0.018118864
9 120 loss: 0.024908386
9 130 loss: 0.03630292
9 140 loss: 0.028759494
9 150 loss: 0.017254619
9 160 loss: 0.011972497
9 170 loss: 0.014511421
9 180 loss: 0.0021370016
9 190 loss: 0.005043111
9 200 loss: 0.013106926
9 210 loss: 0.012918629
9 220 loss: 0.0026622072
9 230 loss: 0.00044469835
9 evaluation acc: 0.985
10 0 loss: 0.029216524
10 10 loss: 0.022603896
10 20 loss: 0.015206694
10 30 loss: 0.019899292
10 40 loss: 0.0071838326
10 50 loss: 0.007734169
10 60 loss: 0.01905264
10 70 loss: 0.016376466
10 80 loss: 0.007521597
10 90 loss: 0.015818022
10 100 loss: 0.040079974
10 110 loss: 0.022278005
10 120 loss: 0.028639428
10 130 loss: 0.01940289
10 140 loss: 0.011545139
10 150 loss: 0.013538317
10 160 loss: 0.009241985
10 170 loss: 0.03183797
10 180 loss: 0.010820968
10 190 loss: 0.013754189
10 200 loss: 0.018092481
10 210 loss: 0.018025195
10 220 loss: 0.0029523661
10 230 loss: 0.0022137074
10 evaluation acc: 0.9884
11 0 loss: 0.011359204
11 10 loss: 0.008258219
11 20 loss: 0.014775935
11 30 loss: 0.0032868143
11 40 loss: 0.010084719
11 50 loss: 0.008483034
11 60 loss: 0.027504222
11 70 loss: 0.013973441
11 80 loss: 0.051034883
11 90 loss: 0.007060394
11 100 loss: 0.007437152
11 110 loss: 0.0053730304
11 120 loss: 0.01665372
11 130 loss: 0.030107684
11 140 loss: 0.0070131165
11 150 loss: 0.044855393
11 160 loss: 0.0093998965
11 170 loss: 0.014633326
11 180 loss: 0.010066226
11 190 loss: 0.0029384855
11 200 loss: 0.02102471
11 210 loss: 0.0049377517
11 220 loss: 0.011845667
11 230 loss: 9.130307e-05
11 evaluation acc: 0.9864
12 0 loss: 0.01292612
12 10 loss: 0.057408165
12 20 loss: 0.014872666
12 30 loss: 0.010431195
12 40 loss: 0.0030338438
12 50 loss: 0.0016576361
12 60 loss: 0.0050583333
12 70 loss: 0.0074946396
12 80 loss: 0.010277768
12 90 loss: 0.0021390445
12 100 loss: 0.039094705
12 110 loss: 0.009811277
12 120 loss: 0.018508159
12 130 loss: 0.032080967
12 140 loss: 0.0055393865
12 150 loss: 0.01031378
12 160 loss: 0.024107046
12 170 loss: 0.012460245
12 180 loss: 0.010134656
12 190 loss: 0.0042545367
12 200 loss: 0.024457354
12 210 loss: 0.03220047
12 220 loss: 0.0067636073
12 230 loss: 9.3517505e-05
12 evaluation acc: 0.9897
13 0 loss: 0.013950869
13 10 loss: 0.014982905
13 20 loss: 0.014947284
13 30 loss: 0.0034427284
13 40 loss: 0.102418534
13 50 loss: 0.015069748
13 60 loss: 0.016687358
13 70 loss: 0.012825226
13 80 loss: 0.021399401
13 90 loss: 0.028735187
13 100 loss: 0.024639117
13 110 loss: 0.007201992
13 120 loss: 0.060734697
13 130 loss: 0.02431567
13 140 loss: 0.019537859
13 150 loss: 0.016699847
13 160 loss: 0.02249654
13 170 loss: 0.002501695
13 180 loss: 0.012419794
13 190 loss: 0.0009445788
13 200 loss: 0.026341418
13 210 loss: 0.00929682
13 220 loss: 0.016183209
13 230 loss: 5.662327e-05
13 evaluation acc: 0.9906
14 0 loss: 0.006411274
14 10 loss: 0.036279652
14 20 loss: 0.013743016
14 30 loss: 0.022141922
14 40 loss: 0.0005435867
14 50 loss: 0.007971241
14 60 loss: 0.009884857
14 70 loss: 0.017875398
14 80 loss: 0.020197285
14 90 loss: 0.03492596
14 100 loss: 0.015374543
14 110 loss: 0.005857695
14 120 loss: 0.022790078
14 130 loss: 0.008472245
14 140 loss: 0.0033093262
14 150 loss: 0.032745555
14 160 loss: 0.0042778268
14 170 loss: 0.0031445439
14 180 loss: 0.0061547607
14 190 loss: 0.01678063
14 200 loss: 0.037504837
14 210 loss: 0.0023027454
14 220 loss: 0.012358449
14 230 loss: 2.4328961e-05
14 evaluation acc: 0.9882
15 0 loss: 0.015048792
15 10 loss: 0.04594824
15 20 loss: 0.010864538
15 30 loss: 0.03150646
15 40 loss: 0.036828507
15 50 loss: 0.011680175
15 60 loss: 0.0051097004
15 70 loss: 0.0039503993
15 80 loss: 0.0031375543
15 90 loss: 0.009147284
15 100 loss: 0.01464734
15 110 loss: 0.0028547754
15 120 loss: 0.015854534
15 130 loss: 0.004660046
15 140 loss: 0.0071911365
15 150 loss: 0.0050878795
15 160 loss: 0.020455923
15 170 loss: 0.012422859
15 180 loss: 0.012573696
15 190 loss: 0.00030559913
15 200 loss: 0.0066040717
15 210 loss: 0.03116747
15 220 loss: 0.071861826
15 230 loss: 1.1780925e-05
15 evaluation acc: 0.9887
16 0 loss: 0.013739326
16 10 loss: 0.049323052
16 20 loss: 0.02547291
16 30 loss: 0.002500833
16 40 loss: 0.030817147
16 50 loss: 0.007632687
16 60 loss: 0.0032654854
16 70 loss: 0.014359873
16 80 loss: 0.008528785
16 90 loss: 0.0055056503
16 100 loss: 0.01220093
16 110 loss: 0.01467837
16 120 loss: 0.061516013
16 130 loss: 0.028886203
16 140 loss: 0.016072009
16 150 loss: 0.02339026
16 160 loss: 0.0055957525
16 170 loss: 0.0124167325
16 180 loss: 0.0045253164
16 190 loss: 0.0009822951
16 200 loss: 0.009500997
16 210 loss: 0.0052198702
16 220 loss: 0.001725527
16 230 loss: 1.0621497e-06
16 evaluation acc: 0.9898
17 0 loss: 0.0051477323
17 10 loss: 0.004106771
17 20 loss: 0.011844339
17 30 loss: 0.024565797
17 40 loss: 0.0071953274
17 50 loss: 0.009152474
17 60 loss: 0.017110491
17 70 loss: 0.008230458
17 80 loss: 0.011587694
17 90 loss: 0.017035408
17 100 loss: 0.03902391
17 110 loss: 0.032596797
17 120 loss: 0.014152733
17 130 loss: 0.019466776
17 140 loss: 0.012716684
17 150 loss: 0.013180938
17 160 loss: 0.0016021885
17 170 loss: 0.0037705062
17 180 loss: 0.0071288976
17 190 loss: 0.0014291534
17 200 loss: 0.065707825
17 210 loss: 0.015961638
17 220 loss: 0.0062098214
17 230 loss: 3.994017e-05
17 evaluation acc: 0.9881
18 0 loss: 0.06714873
18 10 loss: 0.009206182
18 20 loss: 0.010925056
18 30 loss: 0.004415289
18 40 loss: 0.040388916
18 50 loss: 0.009586256
18 60 loss: 0.0028239838
18 70 loss: 0.021794785
18 80 loss: 0.0038602399
18 90 loss: 0.009694032
18 100 loss: 0.019696472
18 110 loss: 0.035842836
18 120 loss: 0.009814732
18 130 loss: 0.023029547
18 140 loss: 0.0043297317
18 150 loss: 0.012666777
18 160 loss: 0.01008877
18 170 loss: 0.011733685
18 180 loss: 0.0056282035
18 190 loss: 0.021115853
18 200 loss: 0.0010529292
18 210 loss: 0.000686461
18 220 loss: 0.013664704
18 230 loss: 1.6502583e-05
18 evaluation acc: 0.9903
19 0 loss: 0.0086883195
19 10 loss: 0.03711572
19 20 loss: 0.014617747
19 30 loss: 0.021040294
19 40 loss: 0.00041153692
19 50 loss: 0.0052810623
19 60 loss: 0.03701656
19 70 loss: 0.001248583
19 80 loss: 0.0014870544
19 90 loss: 3.0314714e-05
19 100 loss: 0.034148507
19 110 loss: 0.0036406494
19 120 loss: 0.028278137
19 130 loss: 0.021077396
19 140 loss: 0.0065290486
19 150 loss: 0.012808228
19 160 loss: 0.00981623
19 170 loss: 0.01855041
19 180 loss: 0.00704238
19 190 loss: 0.00041453447
19 200 loss: 0.0040924544
19 210 loss: 0.0017783365
19 220 loss: 0.0180619
19 230 loss: 0.00018770964
19 evaluation acc: 0.9893
20 0 loss: 0.0042306418
20 10 loss: 0.003719484
20 20 loss: 0.009504665
20 30 loss: 0.007830998
20 40 loss: 0.0017733284
20 50 loss: 0.003131201
20 60 loss: 0.04549117
20 70 loss: 0.006793705
20 80 loss: 0.006782481
20 90 loss: 0.0006178776
20 100 loss: 0.00013203619
20 110 loss: 0.034159806
20 120 loss: 0.0030439342
20 130 loss: 0.01902312
20 140 loss: 0.0044277455
20 150 loss: 0.006019415
20 160 loss: 0.001348566
20 170 loss: 0.005232794
20 180 loss: 0.0036491533
20 190 loss: 0.0013918625
20 200 loss: 0.039423894
20 210 loss: 0.0041019577
20 220 loss: 0.011277183
20 230 loss: 5.215067e-07
20 evaluation acc: 0.9925
21 0 loss: 0.015997712
21 10 loss: 0.0030197357
21 20 loss: 0.0070679314
21 30 loss: 0.00083201774
21 40 loss: 0.021381207
21 50 loss: 0.00394723
21 60 loss: 0.008237252
21 70 loss: 0.00876748
21 80 loss: 0.010408636
21 90 loss: 0.00033265117
21 100 loss: 0.013132071
21 110 loss: 0.05513816
21 120 loss: 0.023371212
21 130 loss: 0.012276446
21 140 loss: 0.012773107
21 150 loss: 0.0050224573
21 160 loss: 0.013807079
21 170 loss: 0.009263824
21 180 loss: 0.035547607
21 190 loss: 0.0013480684
21 200 loss: 0.010971836
21 210 loss: 0.011661466
21 220 loss: 0.017991412
21 230 loss: 7.4123536e-06
21 evaluation acc: 0.9905
22 0 loss: 0.0014609564
22 10 loss: 0.0013178092
22 20 loss: 0.0045323954
22 30 loss: 0.0048575173
22 40 loss: 0.02090382
22 50 loss: 0.015416093
22 60 loss: 0.0054528387
22 70 loss: 0.0076738447
22 80 loss: 0.0030168875
22 90 loss: 0.0008589548
22 100 loss: 0.0029895674
22 110 loss: 0.0019481278
22 120 loss: 0.0059053744
22 130 loss: 0.009862967
22 140 loss: 0.00014047856
22 150 loss: 0.013249129
22 160 loss: 0.0017704484
22 170 loss: 0.009072804
22 180 loss: 0.0041398904
22 190 loss: 0.018675806
22 200 loss: 0.006970229
22 210 loss: 0.0022974901
22 220 loss: 0.0042060222
22 230 loss: 1.124061e-06
22 evaluation acc: 0.9879
23 0 loss: 0.016574945
23 10 loss: 0.031228008
23 20 loss: 0.03725172
23 30 loss: 0.004926192
23 40 loss: 0.0035116305
23 50 loss: 0.0029256453
23 60 loss: 0.00018538488
23 70 loss: 0.004429932
23 80 loss: 0.0015298983
23 90 loss: 0.00045723483
23 100 loss: 0.007920127
23 110 loss: 0.0038660713
23 120 loss: 0.006211835
23 130 loss: 0.016127944
23 140 loss: 0.015721409
23 150 loss: 0.002578491
23 160 loss: 0.0023724556
23 170 loss: 0.019550838
23 180 loss: 0.0014778023
23 190 loss: 6.802064e-05
23 200 loss: 0.009304511
23 210 loss: 0.0026868817
23 220 loss: 0.004466067
23 230 loss: 1.9930019e-07
23 evaluation acc: 0.9862
24 0 loss: 0.055661652
24 10 loss: 0.046412077
24 20 loss: 0.04858519
24 30 loss: 0.034343936
24 40 loss: 0.011484113
24 50 loss: 0.011095522
24 60 loss: 0.001018645
24 70 loss: 0.008379787
24 80 loss: 0.0033080652
24 90 loss: 0.009571689
24 100 loss: 0.001838557
24 110 loss: 0.0021433223
24 120 loss: 0.01952827
24 130 loss: 0.0032160878
24 140 loss: 0.008387647
24 150 loss: 0.0072597563
24 160 loss: 0.007903471
24 170 loss: 0.0056161066
24 180 loss: 0.003590344
24 190 loss: 0.012822665
24 200 loss: 0.029038684
24 210 loss: 0.0065049855
24 220 loss: 0.008020391
24 230 loss: 3.5156611e-07
24 evaluation acc: 0.9873
25 0 loss: 0.004874949
25 10 loss: 0.008596873
25 20 loss: 0.14945365
25 30 loss: 0.0445929
25 40 loss: 0.0139382295
25 50 loss: 0.012882388
25 60 loss: 0.027101977
25 70 loss: 0.0022598093
25 80 loss: 0.0107148485
25 90 loss: 0.016620254
25 100 loss: 0.018026873
25 110 loss: 0.0023844622
25 120 loss: 0.0060365326
25 130 loss: 0.011187035
25 140 loss: 0.0016301489
25 150 loss: 0.013535485
25 160 loss: 0.0044746925
25 170 loss: 0.0011601915
25 180 loss: 0.01066801
25 190 loss: 0.00043665073
25 200 loss: 0.0289311
25 210 loss: 0.0071093524
25 220 loss: 0.0031437394
25 230 loss: 7.273791e-06
25 evaluation acc: 0.991
26 0 loss: 0.013503526
26 10 loss: 0.002324691
26 20 loss: 0.0058722747
26 30 loss: 0.0007604889
26 40 loss: 0.012852313
26 50 loss: 0.00994375
26 60 loss: 0.01681465
26 70 loss: 0.024891626
26 80 loss: 0.005942002
26 90 loss: 0.0004149571
26 100 loss: 0.003812364
26 110 loss: 0.0010971366
26 120 loss: 0.022298165
26 130 loss: 0.00349269
26 140 loss: 0.0025434585
26 150 loss: 0.045990374
26 160 loss: 0.02211481
26 170 loss: 0.0028658472
26 180 loss: 0.008949588
26 190 loss: 0.00039445783
26 200 loss: 0.022987137
26 210 loss: 0.039838497
26 220 loss: 0.01468829
26 230 loss: 2.8333374e-05
26 evaluation acc: 0.9922
27 0 loss: 0.0093964385
27 10 loss: 0.010255553
27 20 loss: 0.0009575664
27 30 loss: 0.011065942
27 40 loss: 0.0030624887
27 50 loss: 0.0044991644
27 60 loss: 0.01451334
27 70 loss: 0.00030417985
27 80 loss: 0.018573446
27 90 loss: 0.041570496
27 100 loss: 0.0054262667
27 110 loss: 0.015853517
27 120 loss: 0.025006179
27 130 loss: 0.025131607
27 140 loss: 0.019538425
27 150 loss: 0.012712437
27 160 loss: 0.0045626196
27 170 loss: 0.0005596338
27 180 loss: 0.005929945
27 190 loss: 0.004634907
27 200 loss: 0.008357166
27 210 loss: 0.00373977
27 220 loss: 0.018996153
27 230 loss: 1.6473555e-06
27 evaluation acc: 0.9905
28 0 loss: 0.0012488593
28 10 loss: 0.020861097
28 20 loss: 0.00016833897
28 30 loss: 0.008399672
28 40 loss: 0.00074692536
28 50 loss: 0.017477192
28 60 loss: 0.00028999525
28 70 loss: 0.0064432938
28 80 loss: 0.0009936005
28 90 loss: 0.0011297354
28 100 loss: 0.008714332
28 110 loss: 3.9877166e-05
28 120 loss: 0.00156477
28 130 loss: 0.0065338966
28 140 loss: 0.0005700362
28 150 loss: 0.025739038
28 160 loss: 0.0026841196
28 170 loss: 0.014361255
28 180 loss: 0.010454309
28 190 loss: 0.006400739
28 200 loss: 0.005942501
28 210 loss: 0.031593665
28 220 loss: 0.0076786294
28 230 loss: 2.4474899e-05
28 evaluation acc: 0.9877
29 0 loss: 0.02162796
29 10 loss: 0.010542171
29 20 loss: 0.0010915817
29 30 loss: 0.00052469363
29 40 loss: 0.011393651
29 50 loss: 0.0014796038
29 60 loss: 0.019457437
29 70 loss: 0.002726095
29 80 loss: 0.019473966
29 90 loss: 0.02850265
29 100 loss: 0.011571399
29 110 loss: 0.008037121
29 120 loss: 0.0045200097
29 130 loss: 0.0021082917
29 140 loss: 0.0011620815
29 150 loss: 0.00054677844
29 160 loss: 0.0056310473
29 170 loss: 0.0042780973
29 180 loss: 0.0057475837
29 190 loss: 0.0022197757
29 200 loss: 0.0007869867
29 210 loss: 0.00018988093
29 220 loss: 0.0008842038
29 230 loss: 0.00041652334
29 evaluation acc: 0.9896
30 0 loss: 0.020874744
30 10 loss: 0.0035479395
30 20 loss: 0.0030532712
30 30 loss: 0.00059816
30 40 loss: 0.0064836917
30 50 loss: 0.0047366368
30 60 loss: 1.5697162e-05
30 70 loss: 0.00025871443
30 80 loss: 0.015647117
30 90 loss: 0.00010502884
30 100 loss: 0.011374777
30 110 loss: 0.010242195
30 120 loss: 0.00016608834
30 130 loss: 0.012820426
30 140 loss: 0.00085638015
30 150 loss: 0.007695699
30 160 loss: 0.00072090613
30 170 loss: 0.00030477918
30 180 loss: 0.019097334
30 190 loss: 0.011359243
30 200 loss: 0.0008162101
30 210 loss: 0.00070718926
30 220 loss: 0.011238273
30 230 loss: 0.0020118444
30 evaluation acc: 0.9924
31 0 loss: 0.00024887803
31 10 loss: 0.0008363528
31 20 loss: 0.030044064
31 30 loss: 0.0012328267
31 40 loss: 0.00021068023
31 50 loss: 0.010287737
31 60 loss: 0.00186296
31 70 loss: 1.1330576e-05
31 80 loss: 9.343416e-05
31 90 loss: 3.2638923e-06
31 100 loss: 0.02300996
31 110 loss: 0.0006064198
31 120 loss: 0.0074316985
31 130 loss: 0.03210479
31 140 loss: 0.0014048653
31 150 loss: 0.00019607996
31 160 loss: 0.0023415189
31 170 loss: 0.0007187237
31 180 loss: 0.019415576
31 190 loss: 0.0005226421
31 200 loss: 0.06192568
31 210 loss: 0.0012893251
31 220 loss: 0.0006849183
31 230 loss: 4.6516576e-05
31 evaluation acc: 0.9915
32 0 loss: 0.030394755
32 10 loss: 0.0032382081
32 20 loss: 0.005800846
32 30 loss: 0.0064999294
32 40 loss: 0.0017246637
32 50 loss: 0.0052914973
32 60 loss: 0.00014395168
32 70 loss: 0.000760581
32 80 loss: 0.0059420173
32 90 loss: 0.0016918456
32 100 loss: 0.008395028
32 110 loss: 0.0010958546
32 120 loss: 0.005320337
32 130 loss: 0.0459594
32 140 loss: 0.012983877
32 150 loss: 0.01641825
32 160 loss: 0.0036158038
32 170 loss: 0.007476726
32 180 loss: 0.0049519837
32 190 loss: 0.0021306132
32 200 loss: 0.0007795205
32 210 loss: 0.00033067795
32 220 loss: 0.0021912362
32 230 loss: 1.5197479e-06
32 evaluation acc: 0.9873
33 0 loss: 0.01197355
33 10 loss: 0.018781973
33 20 loss: 0.019010646
33 30 loss: 0.0019875215
33 40 loss: 0.00566945
33 50 loss: 0.0016413385
33 60 loss: 0.0038389745
33 70 loss: 0.009039832
33 80 loss: 0.0009879387
33 90 loss: 9.719893e-05
33 100 loss: 0.03152028
33 110 loss: 0.075538725
33 120 loss: 0.0052826745
33 130 loss: 0.026828077
33 140 loss: 0.00086502946
33 150 loss: 0.006972344
33 160 loss: 0.021045124
33 170 loss: 0.017044766
33 180 loss: 0.0039296187
33 190 loss: 0.00079735304
33 200 loss: 0.0017445816
33 210 loss: 0.007093594
33 220 loss: 0.0055254595
33 230 loss: 3.961987e-06
33 evaluation acc: 0.9927
34 0 loss: 0.00033324552
34 10 loss: 0.0030428441
34 20 loss: 0.0001014018
34 30 loss: 0.0020293065
34 40 loss: 0.018457841
34 50 loss: 0.0011125684
34 60 loss: 0.0002095068
34 70 loss: 0.00013803845
34 80 loss: 0.00093492493
34 90 loss: 0.0026804204
34 100 loss: 0.0011407203
34 110 loss: 0.0016266234
34 120 loss: 0.012753658
34 130 loss: 0.004789698
34 140 loss: 0.017066315
34 150 loss: 0.0014899857
34 160 loss: 0.003192595
34 170 loss: 0.00038565398
34 180 loss: 0.0030715556
34 190 loss: 0.0017106939
34 200 loss: 0.0030762155
34 210 loss: 0.014133652
34 220 loss: 0.01229553
34 230 loss: 1.9790247e-07
34 evaluation acc: 0.9896
35 0 loss: 0.0015685954
35 10 loss: 0.0016440132
35 20 loss: 0.0013497983
35 30 loss: 4.2223677e-05
35 40 loss: 0.00955534
35 50 loss: 0.0010906435
35 60 loss: 0.0015863563
35 70 loss: 0.0006270688
35 80 loss: 0.024352012
35 90 loss: 0.006269009
35 100 loss: 0.0037319316
35 110 loss: 0.0004410868
35 120 loss: 0.0019584596
35 130 loss: 0.0024108551
35 140 loss: 0.00010962881
35 150 loss: 0.021588657
35 160 loss: 0.022483587
35 170 loss: 0.011207396
35 180 loss: 0.0005278232
35 190 loss: 0.0010930897
35 200 loss: 0.0005302067
35 210 loss: 0.016347911
35 220 loss: 0.0041072485
35 230 loss: 8.055915e-08
35 evaluation acc: 0.992
36 0 loss: 0.0009465257
36 10 loss: 0.002263572
36 20 loss: 0.0008591122
36 30 loss: 0.008105264
36 40 loss: 1.792798e-05
36 50 loss: 0.0071114763
36 60 loss: 0.00036369546
36 70 loss: 0.0016555593
36 80 loss: 0.0003134226
36 90 loss: 0.002174903
36 100 loss: 0.00081314065
36 110 loss: 0.005576004
36 120 loss: 0.021934522
36 130 loss: 0.0072115096
36 140 loss: 0.00038378456
36 150 loss: 0.0017565438
36 160 loss: 0.00041149225
36 170 loss: 0.00039190153
36 180 loss: 0.00018561594
36 190 loss: 0.0012770169
36 200 loss: 0.039484117
36 210 loss: 0.0026693908
36 220 loss: 0.010893817
36 230 loss: 1.0717311e-05
36 evaluation acc: 0.9908
37 0 loss: 0.011289072
37 10 loss: 0.00027515762
37 20 loss: 0.0012650281
37 30 loss: 0.00073222147
37 40 loss: 0.0020682476
37 50 loss: 0.004828364
37 60 loss: 0.00022412719
37 70 loss: 0.004034877
37 80 loss: 0.00038419763
37 90 loss: 3.1940417e-05
37 100 loss: 0.0031056844
37 110 loss: 0.0068278597
37 120 loss: 0.0071568736
37 130 loss: 0.016937273
37 140 loss: 0.003250455
37 150 loss: 0.034530517
37 160 loss: 0.010592999
37 170 loss: 0.0015062694
37 180 loss: 0.006201495
37 190 loss: 0.00728486
37 200 loss: 0.00056074583
37 210 loss: 0.029832466
37 220 loss: 0.00024511674
37 230 loss: 7.3830165e-06
37 evaluation acc: 0.9849
38 0 loss: 0.005936427
38 10 loss: 0.030843368
38 20 loss: 0.017636271
38 30 loss: 0.007984742
38 40 loss: 0.028011166
38 50 loss: 0.008857958
38 60 loss: 0.00020817123
38 70 loss: 0.00030801384
38 80 loss: 0.0007973768
38 90 loss: 0.0066806157
38 100 loss: 0.0049794666
38 110 loss: 0.010861
38 120 loss: 0.007013828
38 130 loss: 0.00080700975
38 140 loss: 0.00094327185
38 150 loss: 0.011785439
38 160 loss: 0.00523002
38 170 loss: 0.0029159233
38 180 loss: 0.00092631375
38 190 loss: 0.001405351
38 200 loss: 0.006313665
38 210 loss: 0.0054003885
38 220 loss: 0.005936282
38 230 loss: 0.00014883353
38 evaluation acc: 0.9894
39 0 loss: 0.00040164345
39 10 loss: 0.002883092
39 20 loss: 0.0032265803
39 30 loss: 0.00091183255
39 40 loss: 0.000979842
39 50 loss: 0.0003934021
39 60 loss: 0.0005573388
39 70 loss: 6.8378845e-06
39 80 loss: 0.0017174304
39 90 loss: 0.0032151532
39 100 loss: 0.0037693214
39 110 loss: 0.006744002
39 120 loss: 0.0009464429
39 130 loss: 0.003594642
39 140 loss: 0.0031514242
39 150 loss: 0.00044832836
39 160 loss: 0.00012462444
39 170 loss: 0.0005908037
39 180 loss: 0.003152837
39 190 loss: 4.115778e-05
39 200 loss: 0.0023306427
39 210 loss: 0.00020151315
39 220 loss: 0.00047348664
39 230 loss: 8.42839e-08
39 evaluation acc: 0.9886
40 0 loss: 0.02292014
40 10 loss: 0.021014927
40 20 loss: 0.0067767235
40 30 loss: 0.00091936433
40 40 loss: 0.05364613
40 50 loss: 0.013402721
40 60 loss: 0.00040532055
40 70 loss: 0.0012463308
40 80 loss: 0.016043385
40 90 loss: 0.015468249
40 100 loss: 0.0060782656
40 110 loss: 0.002119019
40 120 loss: 0.0020470945
40 130 loss: 0.00727319
40 140 loss: 0.000250874
40 150 loss: 0.0018958744
40 160 loss: 0.002114999
40 170 loss: 0.025270183
40 180 loss: 0.007855846
40 190 loss: 0.0048021576
40 200 loss: 0.0004208717
40 210 loss: 0.001379645
40 220 loss: 0.002167135
40 230 loss: 4.2569536e-06
40 evaluation acc: 0.9893
41 0 loss: 0.01234269
41 10 loss: 0.0038899288
41 20 loss: 0.0057481206
41 30 loss: 0.00063013285
41 40 loss: 0.00027820215
41 50 loss: 2.3045655e-05
41 60 loss: 0.002400775
41 70 loss: 4.648746e-06
41 80 loss: 6.698539e-05
41 90 loss: 0.0005027647
41 100 loss: 0.0009731369
41 110 loss: 0.000737295
41 120 loss: 0.00060898
41 130 loss: 0.012005318
41 140 loss: 0.005884659
41 150 loss: 0.0051166597
41 160 loss: 0.00037395817
41 170 loss: 0.0002476815
41 180 loss: 0.0054140324
41 190 loss: 0.00031164984
41 200 loss: 0.0008173904
41 210 loss: 0.013680098
41 220 loss: 5.234278e-05
41 230 loss: 9.313222e-09
41 evaluation acc: 0.9902
42 0 loss: 0.0012480903
42 10 loss: 0.0015092093
42 20 loss: 0.0020977007
42 30 loss: 0.0046063806
42 40 loss: 0.00035960702
42 50 loss: 0.00038000228
42 60 loss: 0.007787774
42 70 loss: 3.6731424e-05
42 80 loss: 2.5018438e-05
42 90 loss: 2.9979949e-05
42 100 loss: 0.0007854616
42 110 loss: 0.0028363208
42 120 loss: 0.002143249
42 130 loss: 0.00014630298
42 140 loss: 4.220037e-06
42 150 loss: 0.009515695
42 160 loss: 0.02599414
42 170 loss: 0.0006412847
42 180 loss: 0.0035374693
42 190 loss: 0.00012852988
42 200 loss: 0.007056451
42 210 loss: 0.0023743308
42 220 loss: 0.0032219542
42 230 loss: 8.444613e-06
42 evaluation acc: 0.9917
43 0 loss: 0.00030735103
43 10 loss: 1.0407248e-06
43 20 loss: 0.0014587992
43 30 loss: 0.0066639185
43 40 loss: 0.00040666343
43 50 loss: 0.00045796382
43 60 loss: 0.000101910286
43 70 loss: 0.000260268
43 80 loss: 3.2285963e-05
43 90 loss: 0.001074123
43 100 loss: 0.021324912
43 110 loss: 0.008735413
43 120 loss: 0.05647821
43 130 loss: 0.01584183
43 140 loss: 0.0017379583
43 150 loss: 0.0013283177
43 160 loss: 0.0036374843
43 170 loss: 0.018784884
43 180 loss: 0.00412705
43 190 loss: 0.00040702504
43 200 loss: 0.0012448764
43 210 loss: 0.0001017328
43 220 loss: 0.0001414467
43 230 loss: 7.590255e-08
43 evaluation acc: 0.9898
44 0 loss: 0.001590834
44 10 loss: 0.0014410887
44 20 loss: 0.0014310189
44 30 loss: 0.0008144382
44 40 loss: 0.0024690686
44 50 loss: 0.06977459
44 60 loss: 0.0003400624
44 70 loss: 0.010870132
44 80 loss: 0.00018280801
44 90 loss: 0.006944615
44 100 loss: 0.001685444
44 110 loss: 0.045216296
44 120 loss: 0.046464674
44 130 loss: 0.00927224
44 140 loss: 0.0018458228
44 150 loss: 0.00043571653
44 160 loss: 0.001008427
44 170 loss: 0.0010217186
44 180 loss: 0.0011122678
44 190 loss: 0.0013991676
44 200 loss: 0.028852155
44 210 loss: 0.0011401591
44 220 loss: 0.00032028207
44 230 loss: 7.29636e-07
44 evaluation acc: 0.9894
45 0 loss: 0.011310576
45 10 loss: 0.0003361314
45 20 loss: 0.0067791254
45 30 loss: 0.00011560034
45 40 loss: 1.857461e-05
45 50 loss: 2.9397192e-05
45 60 loss: 0.045045424
45 70 loss: 0.028260464
45 80 loss: 0.0029916724
45 90 loss: 0.0028185893
45 100 loss: 0.00027840122
45 110 loss: 0.00013496821
45 120 loss: 0.0038378653
45 130 loss: 0.0004990974
45 140 loss: 0.0014092509
45 150 loss: 0.0011733321
45 160 loss: 0.0035304488
45 170 loss: 4.523004e-05
45 180 loss: 0.001194789
45 190 loss: 0.00015434045
45 200 loss: 0.031319022
45 210 loss: 0.000146269
45 220 loss: 0.00033589374
45 230 loss: 7.450578e-09
45 evaluation acc: 0.992
46 0 loss: 2.5086807e-05
46 10 loss: 0.013393906
46 20 loss: 0.00046502167
46 30 loss: 0.00013358281
46 40 loss: 0.035483632
46 50 loss: 0.00029774677
46 60 loss: 0.0022641383
46 70 loss: 8.276991e-05
46 80 loss: 0.0053596334
46 90 loss: 8.163052e-05
46 100 loss: 3.817228e-05
46 110 loss: 0.00018175018
46 120 loss: 0.015781123
46 130 loss: 0.015556313
46 140 loss: 0.028131923
46 150 loss: 0.0040746043
46 160 loss: 0.0040883664
46 170 loss: 0.004606154
46 180 loss: 0.009502195
46 190 loss: 0.021979308
46 200 loss: 0.00028629554
46 210 loss: 0.01620563
46 220 loss: 0.0008224905
46 230 loss: 2.3043931e-05
46 evaluation acc: 0.9888
47 0 loss: 0.0019635896
47 10 loss: 0.0027772584
47 20 loss: 0.00034874203
47 30 loss: 0.010693931
47 40 loss: 0.031995602
47 50 loss: 0.001177294
47 60 loss: 0.00024010177
47 70 loss: 5.712881e-05
47 80 loss: 0.010071862
47 90 loss: 0.00032686527
47 100 loss: 0.018871164
47 110 loss: 0.00964851
47 120 loss: 0.000513782
47 130 loss: 0.002220508
47 140 loss: 0.0007406713
47 150 loss: 0.00086320145
47 160 loss: 0.0028038842
47 170 loss: 0.00012548223
47 180 loss: 0.00039204772
47 190 loss: 0.0006866582
47 200 loss: 0.0003919154
47 210 loss: 3.717065e-05
47 220 loss: 9.821186e-05
47 230 loss: 3.2261773e-06
47 evaluation acc: 0.9887
48 0 loss: 0.0037493198
48 10 loss: 7.086527e-05
48 20 loss: 0.00062923064
48 30 loss: 7.388377e-05
48 40 loss: 2.3649636e-06
48 50 loss: 0.0016613954
48 60 loss: 0.0024236552
48 70 loss: 9.045922e-05
48 80 loss: 2.4078881e-06
48 90 loss: 6.117073e-05
48 100 loss: 3.380683e-06
48 110 loss: 0.00026304647
48 120 loss: 0.00079073146
48 130 loss: 0.00883273
48 140 loss: 3.9776107e-05
48 150 loss: 0.0013909903
48 160 loss: 0.00036117894
48 170 loss: 0.00045157757
48 180 loss: 9.032211e-05
48 190 loss: 0.00017156532
48 200 loss: 0.0004559531
48 210 loss: 0.0007366274
48 220 loss: 5.1255498e-05
48 230 loss: 3.836104e-06
48 evaluation acc: 0.9915
49 0 loss: 6.886011e-05
49 10 loss: 7.2604125e-05
49 20 loss: 0.0011069273
49 30 loss: 0.0001953044
49 40 loss: 2.5475816e-05
49 50 loss: 0.00020517242
49 60 loss: 0.011391344
49 70 loss: 2.4143463e-05
49 80 loss: 0.0013420688
49 90 loss: 0.00017515605
49 100 loss: 0.0066747786
49 110 loss: 0.0014225473
49 120 loss: 0.00089611043
49 130 loss: 0.0015403588
49 140 loss: 0.002230351
49 150 loss: 0.010036581
49 160 loss: 0.0008890041
49 170 loss: 0.008916297
49 180 loss: 0.00034478566
49 190 loss: 0.052513935
49 200 loss: 0.0002728515
49 210 loss: 0.023570769
49 220 loss: 0.006187529
49 230 loss: 5.662805e-06
49 evaluation acc: 0.9911
50 0 loss: 0.009589197
50 10 loss: 0.00043667312
50 20 loss: 0.0010058553
50 30 loss: 0.0012315523
50 40 loss: 0.0002983891
50 50 loss: 0.01063519
50 60 loss: 5.9138398e-05
50 70 loss: 0.0041439347
50 80 loss: 0.014987914
50 90 loss: 0.00019291628
50 100 loss: 0.0061823456
50 110 loss: 0.012660657
50 120 loss: 0.015109426
50 130 loss: 0.012409501
50 140 loss: 0.0006978365
50 150 loss: 0.001730876
50 160 loss: 2.8648841e-05
50 170 loss: 2.5127252e-05
50 180 loss: 0.0043436247
50 190 loss: 8.4380044e-05
50 200 loss: 0.006391169
50 210 loss: 0.00030786806
50 220 loss: 0.0014717632
50 230 loss: 2.7333527e-07
50 evaluation acc: 0.9922
51 0 loss: 0.00025066547
51 10 loss: 0.030139634
51 20 loss: 0.0014314376
51 30 loss: 4.124303e-05
51 40 loss: 0.0002776318
51 50 loss: 0.00039651195
51 60 loss: 0.0005905801
51 70 loss: 9.484942e-05
51 80 loss: 1.916377e-05
51 90 loss: 0.000104344756
51 100 loss: 0.031202538
51 110 loss: 0.0007196611
51 120 loss: 0.0005790509
51 130 loss: 0.00091728545
51 140 loss: 0.011437183
51 150 loss: 0.00030059266
51 160 loss: 2.931175e-05
51 170 loss: 0.0008279125
51 180 loss: 0.0014909032
51 190 loss: 2.6863825e-06
51 200 loss: 0.00031142426
51 210 loss: 0.00077865354
51 220 loss: 0.0047395523
51 230 loss: 2.886082e-06
51 evaluation acc: 0.9883
52 0 loss: 0.0014937277
52 10 loss: 0.00013129058
52 20 loss: 0.00011741645
52 30 loss: 0.0005325495
52 40 loss: 0.05295791
52 50 loss: 0.020260872
52 60 loss: 0.0004902596
52 70 loss: 0.00013567386
52 80 loss: 0.007765793
52 90 loss: 0.0104225585
52 100 loss: 2.0200936e-05
52 110 loss: 0.00020510673
52 120 loss: 0.015910275
52 130 loss: 0.0017586475
52 140 loss: 0.0002532056
52 150 loss: 0.010815558
52 160 loss: 0.00056545506
52 170 loss: 0.00027839403
52 180 loss: 0.0034743433
52 190 loss: 7.6504155e-05
52 200 loss: 0.015636936
52 210 loss: 0.0023956108
52 220 loss: 0.00048536723
52 230 loss: 1.3908627e-06
52 evaluation acc: 0.991
53 0 loss: 0.00053762394
53 10 loss: 0.0045215576
53 20 loss: 0.001558288
53 30 loss: 0.0020097364
53 40 loss: 1.3225435e-05
53 50 loss: 0.001971351
53 60 loss: 0.047017295
53 70 loss: 1.2944664e-06
53 80 loss: 0.041898668
53 90 loss: 0.005984277
53 100 loss: 0.027324732
53 110 loss: 0.0060087037
53 120 loss: 0.0010484327
53 130 loss: 0.003477558
53 140 loss: 0.0006016396
53 150 loss: 0.0013542362
53 160 loss: 0.003442558
53 170 loss: 0.0020777157
53 180 loss: 0.008472128
53 190 loss: 4.129752e-05
53 200 loss: 0.00014165766
53 210 loss: 0.0005540325
53 220 loss: 7.0259855e-05
53 230 loss: 2.805405e-05
53 evaluation acc: 0.9918
54 0 loss: 5.295853e-05
54 10 loss: 2.8281407e-05
54 20 loss: 0.021133818
54 30 loss: 6.9590846e-05
54 40 loss: 0.044445314
54 50 loss: 0.0010791889
54 60 loss: 0.0011561458
54 70 loss: 0.00392847
54 80 loss: 0.0036921918
54 90 loss: 0.019477574
54 100 loss: 0.00040095567
54 110 loss: 0.0007352217
54 120 loss: 4.2391584e-05
54 130 loss: 0.0011603519
54 140 loss: 0.000118164506
54 150 loss: 0.00017591174
54 160 loss: 0.008205973
54 170 loss: 0.0058383257
54 180 loss: 0.00023478329
54 190 loss: 0.0003243173
54 200 loss: 0.0030864407
54 210 loss: 0.0012568182
54 220 loss: 2.1693588e-05
54 230 loss: 2.2358417e-05
54 evaluation acc: 0.9916
55 0 loss: 4.5135832e-05
55 10 loss: 1.2731262e-05
55 20 loss: 2.8117342e-05
55 30 loss: 0.00013446998
55 40 loss: 1.3019055e-05
55 50 loss: 0.00028851844
55 60 loss: 0.00010279743
55 70 loss: 3.4236706e-05
55 80 loss: 6.4642927e-06
55 90 loss: 4.0722578e-05
55 100 loss: 0.004351171
55 110 loss: 3.7899186e-05
55 120 loss: 2.0174507e-06
55 130 loss: 0.0055342126
55 140 loss: 0.00019189126
55 150 loss: 0.00046263688
55 160 loss: 0.0104886005
55 170 loss: 0.00014005412
55 180 loss: 0.027112454
55 190 loss: 0.00045991695
55 200 loss: 4.6663063e-05
55 210 loss: 0.0032171297
55 220 loss: 0.00045380963
55 230 loss: 7.89261e-07
55 evaluation acc: 0.9916
56 0 loss: 0.011298982
56 10 loss: 5.3067513e-05
56 20 loss: 0.0004146642
56 30 loss: 0.000113529946
56 40 loss: 0.0001279204
56 50 loss: 0.0013224683
56 60 loss: 0.00091340614
56 70 loss: 0.0006318789
56 80 loss: 0.00048489321
56 90 loss: 0.0128393425
56 100 loss: 0.0003533714
56 110 loss: 0.0012993152
56 120 loss: 3.8890776e-05
56 130 loss: 0.0001240992
56 140 loss: 1.0212034e-05
56 150 loss: 0.0020673175
56 160 loss: 5.4874617e-05
56 170 loss: 0.00083331316
56 180 loss: 0.008245413
56 190 loss: 0.013379537
56 200 loss: 0.01801483
56 210 loss: 0.0008426551
56 220 loss: 0.011276809
56 230 loss: 2.927921e-06
56 evaluation acc: 0.9902
57 0 loss: 0.0056401524
57 10 loss: 0.0046711713
57 20 loss: 0.0004276301
57 30 loss: 0.00019112542
57 40 loss: 0.00012227283
57 50 loss: 5.5346492e-05
57 60 loss: 0.007902164
57 70 loss: 4.99398e-06
57 80 loss: 1.5682124e-06
57 90 loss: 9.970925e-06
57 100 loss: 0.0004150909
57 110 loss: 5.842545e-06
57 120 loss: 3.054041e-05
57 130 loss: 0.0025471214
57 140 loss: 0.0048726154
57 150 loss: 0.0002902643
57 160 loss: 0.011016555
57 170 loss: 0.0012402623
57 180 loss: 0.02055745
57 190 loss: 0.00014587097
57 200 loss: 0.036247656
57 210 loss: 0.0010152826
57 220 loss: 0.009060196
57 230 loss: 1.0597095e-06
57 evaluation acc: 0.9908
58 0 loss: 0.002625599
58 10 loss: 0.00270982
58 20 loss: 7.218374e-05
58 30 loss: 0.00043737164
58 40 loss: 0.0035001046
58 50 loss: 0.04199692
58 60 loss: 0.0001871254
58 70 loss: 9.299144e-05
58 80 loss: 0.0014531701
58 90 loss: 0.000107144246
58 100 loss: 0.0010629086
58 110 loss: 0.00017098518
58 120 loss: 0.0020809039
58 130 loss: 0.0019561355
58 140 loss: 9.684233e-06
58 150 loss: 0.0005118478
58 160 loss: 0.009409239
58 170 loss: 0.0040125414
58 180 loss: 0.0002540258
58 190 loss: 0.00025526743
58 200 loss: 0.0006102996
58 210 loss: 6.147551e-05
58 220 loss: 6.55422e-05
58 230 loss: 6.0313905e-06
58 evaluation acc: 0.9928
59 0 loss: 0.0009364928
59 10 loss: 4.83743e-05
59 20 loss: 0.00016453076
59 30 loss: 0.0001222686
59 40 loss: 0.0010158861
59 50 loss: 0.00015514622
59 60 loss: 0.00021873966
59 70 loss: 0.0006828873
59 80 loss: 1.9982901e-05
59 90 loss: 3.7130634e-05
59 100 loss: 4.94402e-05
59 110 loss: 0.0017765396
59 120 loss: 0.0038925316
59 130 loss: 0.0007135474
59 140 loss: 1.2953741e-05
59 150 loss: 3.480056e-05
59 160 loss: 0.000742433
59 170 loss: 0.0002750878
59 180 loss: 0.009518438
59 190 loss: 0.00015144028
59 200 loss: 0.010041778
59 210 loss: 0.00032002566
59 220 loss: 0.00016769236
59 230 loss: 5.687678e-06
59 evaluation acc: 0.9914
60 0 loss: 0.0034158714
60 10 loss: 0.00072616537
60 20 loss: 0.00052970817
60 30 loss: 0.00015072941
60 40 loss: 3.9796814e-05
60 50 loss: 3.3886852e-05
60 60 loss: 0.00018649606
60 70 loss: 3.4821112e-06
60 80 loss: 0.04384645
60 90 loss: 0.009513048
60 100 loss: 0.00025252634
60 110 loss: 0.008490059
60 120 loss: 0.0007876865
60 130 loss: 0.0034022597
60 140 loss: 1.7530987e-05
60 150 loss: 4.07001e-05
60 160 loss: 0.0001121643
60 170 loss: 0.041008636
60 180 loss: 4.347824e-05
60 190 loss: 0.0030740239
60 200 loss: 4.1336345e-05
60 210 loss: 3.822491e-05
60 220 loss: 3.1346826e-05
60 230 loss: 2.1810643e-05
60 evaluation acc: 0.9912
61 0 loss: 0.0037514488
61 10 loss: 0.043706704
61 20 loss: 0.0026449624
61 30 loss: 0.008702967
61 40 loss: 0.0050890585
61 50 loss: 0.008822717
61 60 loss: 1.7306185e-05
61 70 loss: 0.00011628405
61 80 loss: 4.9498834e-05
61 90 loss: 4.747969e-05
61 100 loss: 0.0006797055
61 110 loss: 8.2955805e-05
61 120 loss: 0.0029223785
61 130 loss: 0.0017096844
61 140 loss: 0.00024344656
61 150 loss: 0.0024663722
61 160 loss: 5.6029865e-05
61 170 loss: 0.00093999365
61 180 loss: 0.020618077
61 190 loss: 1.5890693e-05
61 200 loss: 0.0062386007
61 210 loss: 0.008827723
61 220 loss: 0.006185406
61 230 loss: 1.320451e-06
61 evaluation acc: 0.991
62 0 loss: 0.00038902284
62 10 loss: 0.0022508558
62 20 loss: 7.290452e-05
62 30 loss: 0.00073080073
62 40 loss: 0.0019673887
62 50 loss: 0.008270106
62 60 loss: 0.0003299167
62 70 loss: 6.547151e-05
62 80 loss: 1.9953968e-05
62 90 loss: 6.25855e-05
62 100 loss: 0.0005248833
62 110 loss: 0.0001834828
62 120 loss: 0.00013085925
62 130 loss: 0.0019756511
62 140 loss: 0.008169139
62 150 loss: 5.654756e-05
62 160 loss: 0.00017262262
62 170 loss: 7.3537965e-05
62 180 loss: 2.2802233e-05
62 190 loss: 1.1824937e-05
62 200 loss: 0.000101567304
62 210 loss: 7.0774564e-05
62 220 loss: 0.00026275052
62 230 loss: 0.0003892837
62 evaluation acc: 0.9904
63 0 loss: 3.4676967e-05
63 10 loss: 2.5441197e-05
63 20 loss: 2.9296627e-05
63 30 loss: 0.00020649486
63 40 loss: 0.0003087146
63 50 loss: 0.00051363144
63 60 loss: 0.003009377
63 70 loss: 0.00020333262
63 80 loss: 1.7759473e-06
63 90 loss: 0.00014515799
63 100 loss: 1.0600634e-05
63 110 loss: 0.0003362154
63 120 loss: 3.4178578e-07
63 130 loss: 0.00069786434
63 140 loss: 6.574782e-07
63 150 loss: 0.020821126
63 160 loss: 0.00033232948
63 170 loss: 1.8940447e-06
63 180 loss: 1.7942008e-05
63 190 loss: 0.009574899
63 200 loss: 0.0019320468
63 210 loss: 0.049383808
63 220 loss: 0.019190699
63 230 loss: 2.950351e-05
63 evaluation acc: 0.9879
64 0 loss: 0.025976187
64 10 loss: 0.032613173
64 20 loss: 0.0033079218
64 30 loss: 0.0066839852
64 40 loss: 0.00017644421
64 50 loss: 0.0025887066
64 60 loss: 0.00852836
64 70 loss: 2.4703517e-05
64 80 loss: 5.852585e-05
64 90 loss: 0.0051386785
64 100 loss: 0.00039850068
64 110 loss: 0.0026018491
64 120 loss: 0.003746471
64 130 loss: 0.00054721424
64 140 loss: 0.021263404
64 150 loss: 0.00040540195
64 160 loss: 0.002690183
64 170 loss: 0.019524423
64 180 loss: 0.00025384748
64 190 loss: 4.9164055e-06
64 200 loss: 0.00056967925
64 210 loss: 0.0002744671
64 220 loss: 0.00011048263
64 230 loss: 3.8322565e-07
64 evaluation acc: 0.9912
65 0 loss: 0.0008826421
65 10 loss: 0.0003400461
65 20 loss: 0.0061929952
65 30 loss: 0.016525745
65 40 loss: 0.006583491
65 50 loss: 3.0755305e-05
65 60 loss: 6.173041e-05
65 70 loss: 0.005996823
65 80 loss: 0.00013235638
65 90 loss: 9.045673e-06
65 100 loss: 0.001676961
65 110 loss: 0.0021637732
65 120 loss: 3.883656e-05
65 130 loss: 0.001517897
65 140 loss: 0.00062951987
65 150 loss: 3.5228597e-05
65 160 loss: 0.00025681045
65 170 loss: 0.0004316596
65 180 loss: 0.0003608299
65 190 loss: 0.0048048454
65 200 loss: 0.00025475933
65 210 loss: 3.0961703e-05
65 220 loss: 0.0007827142
65 230 loss: 2.3934402e-07
65 evaluation acc: 0.9927
66 0 loss: 0.00036958838
66 10 loss: 0.00021371906
66 20 loss: 0.00010199469
66 30 loss: 0.0001971319
66 40 loss: 0.0013619225
66 50 loss: 5.582926e-05
66 60 loss: 0.00031620028
66 70 loss: 0.00042327415
66 80 loss: 0.00022491625
66 90 loss: 2.036145e-06
66 100 loss: 1.24695225e-05
66 110 loss: 0.0003780121
66 120 loss: 0.000451947
66 130 loss: 0.0004951164
66 140 loss: 9.127586e-05
66 150 loss: 1.3391368e-06
66 160 loss: 0.0058741425
66 170 loss: 0.0022319083
66 180 loss: 0.0003743959
66 190 loss: 0.021550823
66 200 loss: 0.00057566835
66 210 loss: 0.0012099317
66 220 loss: 5.451098e-05
66 230 loss: 3.1776133e-05
66 evaluation acc: 0.9921
67 0 loss: 0.0005253985
67 10 loss: 2.0122237e-05
67 20 loss: 0.0015041939
67 30 loss: 9.642431e-06
67 40 loss: 3.82531e-05
67 50 loss: 0.0021220453
67 60 loss: 3.9103794e-05
67 70 loss: 0.0006505048
67 80 loss: 1.4437119e-05
67 90 loss: 4.56574e-05
67 100 loss: 0.00018024333
67 110 loss: 2.0668069e-05
67 120 loss: 0.009666687
67 130 loss: 0.00028080633
67 140 loss: 0.010297129
67 150 loss: 0.008709316
67 160 loss: 2.4797924e-05
67 170 loss: 0.021331498
67 180 loss: 0.004230874
67 190 loss: 0.004164044
67 200 loss: 0.00012067438
67 210 loss: 0.0010014895
67 220 loss: 0.014054072
67 230 loss: 1.1808131e-06
67 evaluation acc: 0.9903
68 0 loss: 0.012508108
68 10 loss: 0.0002455155
68 20 loss: 0.00024736693
68 30 loss: 0.03965711
68 40 loss: 0.0030452446
68 50 loss: 0.0033461
68 60 loss: 0.0013956225
68 70 loss: 5.1983025e-05
68 80 loss: 0.0002583289
68 90 loss: 0.00010226572
68 100 loss: 0.011361311
68 110 loss: 5.0875256e-05
68 120 loss: 3.3522447e-05
68 130 loss: 0.001488432
68 140 loss: 0.004079418
68 150 loss: 1.0396608e-05
68 160 loss: 2.8599185e-05
68 170 loss: 0.0016218065
68 180 loss: 5.039913e-05
68 190 loss: 0.0075443033
68 200 loss: 0.0013935982
68 210 loss: 0.0006392237
68 220 loss: 9.4350275e-05
68 230 loss: 3.421118e-06
68 evaluation acc: 0.9912
69 0 loss: 1.0221742e-05
69 10 loss: 0.0029506283
69 20 loss: 0.018459255
69 30 loss: 0.0017507846
69 40 loss: 0.00029735843
69 50 loss: 0.0002797571
69 60 loss: 9.696177e-05
69 70 loss: 8.519759e-05
69 80 loss: 0.00024243828
69 90 loss: 2.920191e-06
69 100 loss: 0.0017678397
69 110 loss: 7.9119774e-05
69 120 loss: 0.024833817
69 130 loss: 0.0020880182
69 140 loss: 4.894592e-05
69 150 loss: 0.051611908
69 160 loss: 0.00082832016
69 170 loss: 0.00010913131
69 180 loss: 0.00011297743
69 190 loss: 1.3645762e-05
69 200 loss: 0.0007918174
69 210 loss: 0.0023819197
69 220 loss: 4.3558386e-05
69 230 loss: 4.73204e-06
69 evaluation acc: 0.9924
70 0 loss: 0.018191965
70 10 loss: 0.0001464141
70 20 loss: 0.0012683749
70 30 loss: 0.00029612024
70 40 loss: 4.4374992e-05
70 50 loss: 0.01486172
70 60 loss: 0.00031691173
70 70 loss: 0.00037684676
70 80 loss: 0.00014541438
70 90 loss: 0.0016151755
70 100 loss: 0.0038726267
70 110 loss: 0.0004604022
70 120 loss: 0.00027669687
70 130 loss: 0.0036317678
70 140 loss: 0.00032754202
70 150 loss: 5.0281105e-05
70 160 loss: 0.0015063464
70 170 loss: 0.0054762424
70 180 loss: 0.0007668664
70 190 loss: 0.0017238016
70 200 loss: 0.0040034344
70 210 loss: 0.002462184
70 220 loss: 0.00089214306
70 230 loss: 3.953394e-07
70 evaluation acc: 0.9915
71 0 loss: 0.00018250666
71 10 loss: 0.0007753758
71 20 loss: 1.3961273e-05
71 30 loss: 2.5743124e-05
71 40 loss: 0.0003376353
71 50 loss: 0.00021781407
71 60 loss: 1.6598196e-05
71 70 loss: 2.5891968e-06
71 80 loss: 0.00013189031
71 90 loss: 2.334654e-05
71 100 loss: 2.755511e-06
71 110 loss: 3.3102108e-06
71 120 loss: 8.278389e-05
71 130 loss: 0.0031787655
71 140 loss: 1.2245607e-05
71 150 loss: 5.7020905e-05
71 160 loss: 0.00028943125
71 170 loss: 0.00022143281
71 180 loss: 0.00018887463
71 190 loss: 2.7138833e-05
71 200 loss: 0.0007424819
71 210 loss: 2.6135851e-05
71 220 loss: 0.0047079474
71 230 loss: 0.0005190223
71 evaluation acc: 0.9905
72 0 loss: 0.0001035718
72 10 loss: 0.00010798558
72 20 loss: 0.0023954404
72 30 loss: 0.00023200328
72 40 loss: 0.0021853133
72 50 loss: 0.0043040654
72 60 loss: 0.00020598914
72 70 loss: 0.0031495164
72 80 loss: 0.01447624
72 90 loss: 0.011566828
72 100 loss: 0.008874614
72 110 loss: 0.0109629575
72 120 loss: 0.012227798
72 130 loss: 0.0022238144
72 140 loss: 0.0037343903
72 150 loss: 0.00036746496
72 160 loss: 0.00033945998
72 170 loss: 0.00014186393
72 180 loss: 0.00518105
72 190 loss: 0.003062188
72 200 loss: 0.006227314
72 210 loss: 0.00014290956
72 220 loss: 6.620664e-06
72 230 loss: 4.320811e-06
72 evaluation acc: 0.989
73 0 loss: 6.366499e-05
73 10 loss: 8.895082e-05
73 20 loss: 0.012741223
73 30 loss: 0.0045203506
73 40 loss: 0.021293834
73 50 loss: 0.00084588106
73 60 loss: 0.0027603384
73 70 loss: 0.040740453
73 80 loss: 0.001369818
73 90 loss: 0.0051936703
73 100 loss: 0.00013427451
73 110 loss: 3.9877523e-05
73 120 loss: 0.013605869
73 130 loss: 0.0072933678
73 140 loss: 2.4295132e-05
73 150 loss: 0.0045298086
73 160 loss: 0.0011312943
73 170 loss: 0.0028684486
73 180 loss: 0.005552246
73 190 loss: 0.000100015146
73 200 loss: 0.0013914875
73 210 loss: 0.00018184136
73 220 loss: 6.272365e-06
73 230 loss: 1.0244541e-08
73 evaluation acc: 0.9934
74 0 loss: 2.5924983e-05
74 10 loss: 0.005097056
74 20 loss: 3.3606408e-05
74 30 loss: 2.0955067e-05
74 40 loss: 5.9091628e-05
74 50 loss: 3.1567001e-06
74 60 loss: 0.0006703936
74 70 loss: 1.8640761e-05
74 80 loss: 4.31984e-05
74 90 loss: 2.8513425e-06
74 100 loss: 0.0050194515
74 110 loss: 2.4756919e-06
74 120 loss: 0.005565092
74 130 loss: 0.0012509637
74 140 loss: 0.0024154584
74 150 loss: 0.0038104928
74 160 loss: 7.921188e-06
74 170 loss: 0.0016721796
74 180 loss: 1.9016281e-05
74 190 loss: 3.6431582e-05
74 200 loss: 0.003697692
74 210 loss: 4.2023647e-05
74 220 loss: 0.032710813
74 230 loss: 7.754361e-06
74 evaluation acc: 0.9899
75 0 loss: 0.0002147208
75 10 loss: 0.020536572
75 20 loss: 0.00031712145
75 30 loss: 0.003360011
75 40 loss: 0.005298863
75 50 loss: 0.0018684581
75 60 loss: 0.0004905461
75 70 loss: 0.0032826285
75 80 loss: 0.0003338022
75 90 loss: 8.8799665e-05
75 100 loss: 0.0005373965
75 110 loss: 0.00035625394
75 120 loss: 0.0012620655
75 130 loss: 0.002656991
75 140 loss: 0.00074249814
75 150 loss: 0.00020909915
75 160 loss: 0.012388081
75 170 loss: 0.00016133649
75 180 loss: 0.0020899202
75 190 loss: 0.00010322321
75 200 loss: 5.6789827e-06
75 210 loss: 0.00031755707
75 220 loss: 2.716454e-05
75 230 loss: 2.1886045e-08
75 evaluation acc: 0.9906
76 0 loss: 0.0012671999
76 10 loss: 6.505298e-05
76 20 loss: 0.008156241
76 30 loss: 0.0028987352
76 40 loss: 6.822304e-05
76 50 loss: 0.0007781442
76 60 loss: 0.00072918984
76 70 loss: 1.4371032e-05
76 80 loss: 7.9931146e-05
76 90 loss: 0.001209919
76 100 loss: 0.0008774709
76 110 loss: 0.0047977497
76 120 loss: 2.821587e-05
76 130 loss: 0.00010417613
76 140 loss: 0.008122881
76 150 loss: 0.0025496285
76 160 loss: 0.00018773113
76 170 loss: 0.0023970315
76 180 loss: 0.00036617034
76 190 loss: 1.726664e-05
76 200 loss: 0.0008058732
76 210 loss: 0.00040924334
76 220 loss: 0.000378483
76 230 loss: 0.0018987102
76 evaluation acc: 0.9918
77 0 loss: 0.0008342187
77 10 loss: 0.018174998
77 20 loss: 0.000110253895
77 30 loss: 0.00034577117
77 40 loss: 0.0007422108
77 50 loss: 7.895123e-06
77 60 loss: 0.0020646194
77 70 loss: 0.02046138
77 80 loss: 0.016564272
77 90 loss: 0.0011892479
77 100 loss: 0.0056124586
77 110 loss: 8.605986e-05
77 120 loss: 0.00044672273
77 130 loss: 3.7898368e-05
77 140 loss: 0.014715305
77 150 loss: 7.444056e-05
77 160 loss: 0.00012554765
77 170 loss: 0.00031009628
77 180 loss: 0.0042035277
77 190 loss: 7.053451e-06
77 200 loss: 0.0004024501
77 210 loss: 0.00013941502
77 220 loss: 4.564094e-05
77 230 loss: 5.634479e-08
77 evaluation acc: 0.9927
78 0 loss: 0.00018275021
78 10 loss: 0.00024407293
78 20 loss: 0.011985597
78 30 loss: 6.1364362e-06
78 40 loss: 6.897911e-06
78 50 loss: 0.00018303892
78 60 loss: 0.01258907
78 70 loss: 0.00022752814
78 80 loss: 0.0005418848
78 90 loss: 1.5052421e-05
78 100 loss: 0.008431397
78 110 loss: 1.6265254e-05
78 120 loss: 0.000120068566
78 130 loss: 0.00094375876
78 140 loss: 2.646626e-05
78 150 loss: 0.00017318473
78 160 loss: 0.00022476923
78 170 loss: 3.0815247e-06
78 180 loss: 0.0012360807
78 190 loss: 0.0010630795
78 200 loss: 5.7113342e-05
78 210 loss: 0.0026169259
78 220 loss: 0.00027259885
78 230 loss: 6.5192527e-09
78 evaluation acc: 0.9905
79 0 loss: 6.750116e-05
79 10 loss: 0.002444425
79 20 loss: 0.00051294616
79 30 loss: 7.303196e-05
79 40 loss: 0.0072141923
79 50 loss: 0.00040220428
79 60 loss: 0.007252918
79 70 loss: 0.010697938
79 80 loss: 0.0018500551
79 90 loss: 0.0025884267
79 100 loss: 0.000112824295
79 110 loss: 0.010147468
79 120 loss: 0.0016417643
79 130 loss: 0.004714873
79 140 loss: 0.015613312
79 150 loss: 0.022824274
79 160 loss: 0.021185763
79 170 loss: 0.0026057563
79 180 loss: 0.0011299982
79 190 loss: 1.3766046e-05
79 200 loss: 0.0002064756
79 210 loss: 0.0004994772
79 220 loss: 0.00043770886
79 230 loss: 3.0732733e-07
79 evaluation acc: 0.9933
80 0 loss: 0.00062487356
80 10 loss: 2.4142928e-06
80 20 loss: 0.00019592153
80 30 loss: 6.528647e-05
80 40 loss: 7.99068e-05
80 50 loss: 0.02544704
80 60 loss: 0.00017470578
80 70 loss: 0.007820164
80 80 loss: 0.0001282127
80 90 loss: 0.0018592284
80 100 loss: 0.0036604635
80 110 loss: 5.198361e-05
80 120 loss: 1.8364708e-05
80 130 loss: 6.932681e-05
80 140 loss: 5.03319e-06
80 150 loss: 1.0232149e-05
80 160 loss: 7.242538e-05
80 170 loss: 5.1381554e-05
80 180 loss: 0.019036269
80 190 loss: 2.5289231e-05
80 200 loss: 0.0050387494
80 210 loss: 0.00035388253
80 220 loss: 0.00062059384
80 230 loss: 2.4272165e-06
80 evaluation acc: 0.9931
81 0 loss: 3.9876417e-05
81 10 loss: 9.40148e-07
81 20 loss: 0.0015595014
81 30 loss: 0.0014945205
81 40 loss: 9.4193216e-05
81 50 loss: 0.0020382241
81 60 loss: 7.144051e-06
81 70 loss: 5.1686226e-07
81 80 loss: 2.3056018e-06
81 90 loss: 1.6658834e-06
81 100 loss: 9.452897e-08
81 110 loss: 2.39839e-06
81 120 loss: 6.4134e-06
81 130 loss: 1.0221694e-05
81 140 loss: 2.1420407e-08
81 150 loss: 6.214874e-06
81 160 loss: 5.078874e-06
81 170 loss: 1.1649988e-06
81 180 loss: 3.9346905e-05
81 190 loss: 0.0023451378
81 200 loss: 0.00041340364
81 210 loss: 0.00023617329
81 220 loss: 0.0010320053
81 230 loss: 3.1990325e-07
81 evaluation acc: 0.9917
82 0 loss: 0.0014361059
82 10 loss: 0.00044200788
82 20 loss: 1.3797563e-05
82 30 loss: 2.6596854e-05
82 40 loss: 0.0487149
82 50 loss: 0.0017321811
82 60 loss: 0.000972879
82 70 loss: 8.39489e-05
82 80 loss: 0.0012518954
82 90 loss: 1.4684537e-05
82 100 loss: 5.352509e-05
82 110 loss: 0.00014750758
82 120 loss: 0.00013259047
82 130 loss: 0.0005058946
82 140 loss: 2.6365497e-06
82 150 loss: 0.00038427
82 160 loss: 8.0889105e-05
82 170 loss: 3.4581958e-06
82 180 loss: 8.886502e-06
82 190 loss: 0.0003006022
82 200 loss: 2.8311253e-05
82 210 loss: 0.00020212607
82 220 loss: 1.0747978e-05
82 230 loss: 4.154284e-06
82 evaluation acc: 0.9934
83 0 loss: 0.00053276593
83 10 loss: 1.2063835e-05
83 20 loss: 4.4332273e-06
83 30 loss: 0.01467315
83 40 loss: 1.372255e-06
83 50 loss: 0.0005678541
83 60 loss: 5.354861e-07
83 70 loss: 0.0988622
83 80 loss: 0.00012985876
83 90 loss: 0.010177146
83 100 loss: 0.0042025023
83 110 loss: 0.0024260392
83 120 loss: 0.0020327144
83 130 loss: 0.00024803076
83 140 loss: 8.580999e-05
83 150 loss: 2.5798561e-05
83 160 loss: 0.00036195113
83 170 loss: 0.000103613
83 180 loss: 0.004069515
83 190 loss: 0.014901686
83 200 loss: 0.0049240943
83 210 loss: 0.003509633
83 220 loss: 6.0557097e-05
83 230 loss: 1.3832353e-06
83 evaluation acc: 0.9917
84 0 loss: 0.0019628736
84 10 loss: 0.0034526223
84 20 loss: 0.00030612233
84 30 loss: 3.740988e-05
84 40 loss: 2.2347005e-05
84 50 loss: 6.1216642e-06
84 60 loss: 7.182241e-06
84 70 loss: 9.523663e-06
84 80 loss: 0.00010105474
84 90 loss: 0.0015051202
84 100 loss: 0.011234896
84 110 loss: 0.0007028439
84 120 loss: 0.000721017
84 130 loss: 0.00024377508
84 140 loss: 1.559384e-05
84 150 loss: 0.00033593003
84 160 loss: 1.1414705e-05
84 170 loss: 2.0152047e-05
84 180 loss: 8.5028705e-06
84 190 loss: 0.0004925141
84 200 loss: 5.489422e-05
84 210 loss: 0.00025761555
84 220 loss: 0.00030577584
84 230 loss: 9.313189e-08
84 evaluation acc: 0.9929
85 0 loss: 0.00019292664
85 10 loss: 3.8697162e-05
85 20 loss: 7.3555944e-05
85 30 loss: 0.00013686041
85 40 loss: 6.13372e-06
85 50 loss: 2.3918176e-06
85 60 loss: 9.484511e-05
85 70 loss: 1.279552e-06
85 80 loss: 7.0698125e-06
85 90 loss: 8.586528e-07
85 100 loss: 2.2433587e-06
85 110 loss: 2.020954e-07
85 120 loss: 0.0010793778
85 130 loss: 0.00017322064
85 140 loss: 4.4189508e-07
85 150 loss: 0.00012301067
85 160 loss: 2.4191727e-06
85 170 loss: 0.013342585
85 180 loss: 0.0024447462
85 190 loss: 0.0002601964
85 200 loss: 0.017557062
85 210 loss: 0.00011752046
85 220 loss: 0.0009688627
85 230 loss: 5.4386635e-07
85 evaluation acc: 0.9924
86 0 loss: 0.01365852
86 10 loss: 0.00057233055
86 20 loss: 6.830884e-05
86 30 loss: 0.0002175825
86 40 loss: 2.6400908e-06
86 50 loss: 0.0005900726
86 60 loss: 0.00016361426
86 70 loss: 9.1735e-08
86 80 loss: 0.00019252216
86 90 loss: 1.8056497e-06
86 100 loss: 0.00192011
86 110 loss: 9.629482e-07
86 120 loss: 8.025256e-06
86 130 loss: 0.00015711879
86 140 loss: 0.0068383752
86 150 loss: 0.00012244341
86 160 loss: 0.0008024227
86 170 loss: 1.4921932e-05
86 180 loss: 0.0017478294
86 190 loss: 5.9367545e-07
86 200 loss: 1.602909e-05
86 210 loss: 0.025465868
86 220 loss: 0.0004058915
86 230 loss: 1.8626449e-09
86 evaluation acc: 0.9912
87 0 loss: 9.48275e-05
87 10 loss: 0.00020664826
87 20 loss: 0.0068280376
87 30 loss: 0.00024875317
87 40 loss: 2.8364237e-05
87 50 loss: 0.022598946
87 60 loss: 0.007851968
87 70 loss: 0.00031268175
87 80 loss: 0.0006822686
87 90 loss: 6.9821275e-05
87 100 loss: 2.5500174e-05
87 110 loss: 0.002113242
87 120 loss: 0.017900161
87 130 loss: 0.008354221
87 140 loss: 9.608741e-05
87 150 loss: 2.2735398e-05
87 160 loss: 0.0022352682
87 170 loss: 2.600047e-06
87 180 loss: 0.001018024
87 190 loss: 8.9333305e-05
87 200 loss: 0.00046633263
87 210 loss: 0.000120624994
87 220 loss: 0.00024287784
87 230 loss: 1.4295705e-07
87 evaluation acc: 0.9913
88 0 loss: 0.00048860087
88 10 loss: 0.00029540862
88 20 loss: 0.00030404644
88 30 loss: 0.0009807582
88 40 loss: 6.220205e-05
88 50 loss: 1.1766597e-05
88 60 loss: 3.1410516e-05
88 70 loss: 0.00012762414
88 80 loss: 9.845494e-06
88 90 loss: 5.473505e-06
88 100 loss: 0.0017432724
88 110 loss: 8.2405786e-05
88 120 loss: 0.00014598564
88 130 loss: 5.3084474e-05
88 140 loss: 3.8350732e-05
88 150 loss: 0.000112793605
88 160 loss: 5.9944185e-05
88 170 loss: 0.00024844217
88 180 loss: 0.003749973
88 190 loss: 4.3212896e-07
88 200 loss: 9.970245e-06
88 210 loss: 2.4023358e-05
88 220 loss: 0.00012236547
88 230 loss: 1.6298117e-08
88 evaluation acc: 0.9933
89 0 loss: 1.7707865e-05
89 10 loss: 0.0008691517
89 20 loss: 5.9874557e-05
89 30 loss: 1.5313144e-06
89 40 loss: 0.00013982358
89 50 loss: 1.0534735e-05
89 60 loss: 5.379542e-06
89 70 loss: 0.00010255903
89 80 loss: 3.1518706e-05
89 90 loss: 4.0418416e-07
89 100 loss: 2.9522602e-07
89 110 loss: 2.7618207e-05
89 120 loss: 2.603418e-05
89 130 loss: 0.00017489833
89 140 loss: 0.008490194
89 150 loss: 5.5614903e-05
89 160 loss: 0.000114740076
89 170 loss: 2.2644834e-05
89 180 loss: 0.0032303696
89 190 loss: 1.9499898e-06
89 200 loss: 6.233775e-05
89 210 loss: 0.00015953823
89 220 loss: 0.013689611
89 230 loss: 1.8626449e-09
89 evaluation acc: 0.9905
90 0 loss: 0.0080451155
90 10 loss: 0.00027962864
90 20 loss: 5.629415e-05
90 30 loss: 0.00023549219
90 40 loss: 0.059272192
90 50 loss: 0.0079623535
90 60 loss: 0.0013670253
90 70 loss: 0.0011924171
90 80 loss: 0.0012230619
90 90 loss: 5.869318e-06
90 100 loss: 0.020506764
90 110 loss: 5.4463457e-05
90 120 loss: 0.0053074476
90 130 loss: 1.2152726e-05
90 140 loss: 0.00011620535
90 150 loss: 8.8290675e-05
90 160 loss: 0.00095960684
90 170 loss: 0.011772988
90 180 loss: 0.0043815565
90 190 loss: 5.7505174e-05
90 200 loss: 0.00042082855
90 210 loss: 0.00038035453
90 220 loss: 0.0010779975
90 230 loss: 3.114494e-05
90 evaluation acc: 0.989
91 0 loss: 0.002595724
91 10 loss: 0.023226656
91 20 loss: 0.0011956136
91 30 loss: 0.0004222246
91 40 loss: 0.01599033
91 50 loss: 0.005086525
91 60 loss: 0.034765046
91 70 loss: 0.00029648942
91 80 loss: 0.012680549
91 90 loss: 0.0010115971
91 100 loss: 0.00020584775
91 110 loss: 0.0001857156
91 120 loss: 2.5290848e-05
91 130 loss: 0.0011074462
91 140 loss: 3.2485175e-06
91 150 loss: 0.008069362
91 160 loss: 0.0013921162
91 170 loss: 2.7432498e-05
91 180 loss: 5.8764574e-05
91 190 loss: 8.921654e-05
91 200 loss: 0.0004649768
91 210 loss: 0.00025566874
91 220 loss: 5.9307342e-05
91 230 loss: 3.771843e-08
91 evaluation acc: 0.9921
92 0 loss: 4.9914847e-06
92 10 loss: 5.4414828e-05
92 20 loss: 0.00025450828
92 30 loss: 0.00041813092
92 40 loss: 0.01938992
92 50 loss: 0.00018759815
92 60 loss: 6.257825e-06
92 70 loss: 0.00024411656
92 80 loss: 7.512889e-06
92 90 loss: 3.933002e-06
92 100 loss: 1.3737754e-05
92 110 loss: 1.580818e-06
92 120 loss: 1.4455731e-05
92 130 loss: 7.1749935e-05
92 140 loss: 1.586839e-06
92 150 loss: 4.332164e-05
92 160 loss: 5.957972e-05
92 170 loss: 1.3871683e-06
92 180 loss: 0.00019711275
92 190 loss: 9.952962e-05
92 200 loss: 0.000100759564
92 210 loss: 0.010396969
92 220 loss: 6.56173e-06
92 230 loss: 0.0054642875
92 evaluation acc: 0.9906
93 0 loss: 0.008209325
93 10 loss: 0.0001598178
93 20 loss: 0.002237009
93 30 loss: 4.8199632e-05
93 40 loss: 0.0034934543
93 50 loss: 0.00059266965
93 60 loss: 0.006682801
93 70 loss: 0.0031225365
93 80 loss: 6.208837e-05
93 90 loss: 2.2295353e-06
93 100 loss: 1.1962502e-06
93 110 loss: 0.0005539635
93 120 loss: 0.0040037227
93 130 loss: 6.1008708e-05
93 140 loss: 1.2201385e-05
93 150 loss: 2.1632784e-05
93 160 loss: 0.00017076005
93 170 loss: 0.0024805302
93 180 loss: 0.029753609
93 190 loss: 2.713122e-05
93 200 loss: 5.578556e-05
93 210 loss: 0.00087357697
93 220 loss: 0.00035465255
93 230 loss: 4.423757e-08
93 evaluation acc: 0.9924
94 0 loss: 0.00057258643
94 10 loss: 0.0008605945
94 20 loss: 0.00043710458
94 30 loss: 0.00015293882
94 40 loss: 1.0753802e-05
94 50 loss: 0.00048073663
94 60 loss: 0.014901565
94 70 loss: 6.6260844e-07
94 80 loss: 0.0017785323
94 90 loss: 0.00015713026
94 100 loss: 0.0013791659
94 110 loss: 2.800008e-05
94 120 loss: 0.000163496
94 130 loss: 0.00044978986
94 140 loss: 7.9943115e-05
94 150 loss: 0.00010170636
94 160 loss: 0.00012372952
94 170 loss: 4.5540045e-07
94 180 loss: 0.00010824444
94 190 loss: 4.498185e-07
94 200 loss: 1.3582504e-06
94 210 loss: 9.910728e-06
94 220 loss: 4.7103807e-05
94 230 loss: 7.916237e-09
94 evaluation acc: 0.99
95 0 loss: 0.00618885
95 10 loss: 2.548923e-06
95 20 loss: 6.779493e-05
95 30 loss: 0.0005493921
95 40 loss: 0.00013016694
95 50 loss: 0.0006282493
95 60 loss: 0.024598528
95 70 loss: 1.1724815e-06
95 80 loss: 0.008705078
95 90 loss: 0.00094364304
95 100 loss: 1.0167105e-05
95 110 loss: 0.0012376517
95 120 loss: 0.0053906003
95 130 loss: 0.0034068595
95 140 loss: 0.004267505
95 150 loss: 0.006586429
95 160 loss: 0.0013234926
95 170 loss: 0.0002861624
95 180 loss: 2.9760646e-05
95 190 loss: 0.00014913703
95 200 loss: 0.0011769693
95 210 loss: 0.002238703
95 220 loss: 0.0012600245
95 230 loss: 2.6588975e-07
95 evaluation acc: 0.9895
96 0 loss: 0.016850924
96 10 loss: 0.012085942
96 20 loss: 0.0008516957
96 30 loss: 0.01636174
96 40 loss: 0.009906918
96 50 loss: 0.0012423978
96 60 loss: 5.115189e-05
96 70 loss: 9.135603e-06
96 80 loss: 0.001250721
96 90 loss: 0.0006181032
96 100 loss: 0.003234426
96 110 loss: 0.0022620705
96 120 loss: 0.0034980306
96 130 loss: 0.00038062216
96 140 loss: 7.247251e-05
96 150 loss: 0.00018093325
96 160 loss: 0.0009609005
96 170 loss: 0.00024145292
96 180 loss: 0.003172897
96 190 loss: 8.224623e-06
96 200 loss: 0.00027111577
96 210 loss: 5.803667e-05
96 220 loss: 2.7433256e-05
96 230 loss: 9.313217e-09
96 evaluation acc: 0.9925
97 0 loss: 8.2110804e-05
97 10 loss: 5.5857832e-05
97 20 loss: 8.352098e-06
97 30 loss: 0.0003833245
97 40 loss: 1.701348e-05
97 50 loss: 0.00010496086
97 60 loss: 9.529884e-06
97 70 loss: 7.2855444e-05
97 80 loss: 3.7088936e-05
97 90 loss: 7.953708e-05
97 100 loss: 6.894901e-05
97 110 loss: 0.00023515323
97 120 loss: 1.0760695e-06
97 130 loss: 6.0421447e-05
97 140 loss: 9.248003e-06
97 150 loss: 2.2311579e-05
97 160 loss: 0.00017786228
97 170 loss: 3.3388146e-06
97 180 loss: 4.1111075e-06
97 190 loss: 3.3846272e-06
97 200 loss: 9.354494e-07
97 210 loss: 0.00154051
97 220 loss: 5.019866e-06
97 230 loss: 6.053592e-09
97 evaluation acc: 0.9923
98 0 loss: 0.0007136149
98 10 loss: 1.8514562e-05
98 20 loss: 6.0581726e-05
98 30 loss: 1.1838787e-05
98 40 loss: 0.00027550687
98 50 loss: 7.377585e-06
98 60 loss: 3.4598312e-07
98 70 loss: 1.2729957e-05
98 80 loss: 8.628017e-06
98 90 loss: 6.3145762e-06
98 100 loss: 1.0695317e-06
98 110 loss: 0.00018154099
98 120 loss: 2.1943695e-06
98 130 loss: 3.7705235e-05
98 140 loss: 2.8025963e-05
98 150 loss: 3.4986829e-06
98 160 loss: 2.1336175e-06
98 170 loss: 7.841488e-07
98 180 loss: 6.0430493e-06
98 190 loss: 7.393755e-06
98 200 loss: 1.4369766e-06
98 210 loss: 9.564171e-07
98 220 loss: 5.2743126e-06
98 230 loss: 0.0
98 evaluation acc: 0.9932
99 0 loss: 6.5236117e-07
99 10 loss: 9.9843455e-05
99 20 loss: 7.1023865e-06
99 30 loss: 3.841641e-07
99 40 loss: 2.8406826e-06
99 50 loss: 4.1210316e-07
99 60 loss: 2.9755392e-07
99 70 loss: 1.44267915e-05
99 80 loss: 2.2997726e-06
99 90 loss: 3.4424556e-05
99 100 loss: 5.0661714e-07
99 110 loss: 1.3605895e-05
99 120 loss: 6.8076827e-07
99 130 loss: 3.903157e-05
99 140 loss: 2.060242e-06
99 150 loss: 3.0424078e-06
99 160 loss: 7.3244223e-07
99 170 loss: 5.200338e-06
99 180 loss: 4.594187e-06
99 190 loss: 2.5146687e-06
99 200 loss: 4.7636414e-07
99 210 loss: 8.297527e-07
99 220 loss: 3.967488e-06
99 230 loss: 0.0
99 evaluation acc: 0.9933
